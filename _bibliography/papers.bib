---
---

@misc{beaudouin2025deltavelocityrectifiedflow,
      title={Delta Velocity Rectified Flow for Text-to-Image Editing}, 
      author={Gaspard Beaudouin and Minghan Li and Jaeyeon Kim and Sung-Hoon Yoon and Mengyu Wang},
      year={2025},
      eprint={2509.05342},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2509.05342}, 
}

@inproceedings{yoon2025splitflow,
      title={SplitFlow: Flow Decomposition for Inversion-Free Text-to-Image Editing},
      author={Sung-Hoon Yoon and Minghan Li and Gaspard Beaudouin and Congcong Wen and Muhammad Azhar and Mengyu Wang},
      booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
      year={2025},
      url={https://neurips.cc/virtual/2025/poster/116281},
      abstract={Rectified flow models have become a de facto standard in image generation due to their stable sampling trajectories and high-fidelity outputs. Despite their strong generative capabilities, they face critical limitations in image editing tasks: inaccurate inversion processes for mapping real images back into the latent space, and gradient entanglement issues during editing often result in outputs that do not faithfully reflect the target prompt. Recent efforts have attempted to directly map source and target distributions via ODE-based approaches without inversion; however, these methods still yield suboptimal editing quality. In this work, we propose a flow decomposition-and-aggregation framework built upon an inversion-free formulation to address these limitations. Specifically, we semantically decompose the target prompt into multiple sub-prompts, compute an independent flow for each, and aggregate them to form a unified editing trajectory. While we empirically observe that decomposing the original flow enhances diversity in the target space, generating semantically aligned outputs still requires consistent guidance toward the full target prompt. To this end, we design a cosine similarity-based soft aggregation mechanism inspired by gradient conflict resolution in multi-task learning. This approach adaptively weights the sub-target velocity fields, suppressing semantic redundancy while emphasizing distinct directions, thereby preserving both diversity and consistency in the final edited output. Experimental results demonstrate that our method outperforms existing zero-shot editing approaches in terms of semantic fidelity and attribute disentanglement.}
}